{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from glob import glob\n",
    "import functools\n",
    "import json\n",
    "import re\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\", context=\"notebook\", palette=sns.color_palette(\"rocket\", 4))\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 100)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all results\n",
    "results_files = sorted(glob(f\"results/*.json\"))\n",
    "all_results = []\n",
    "# store layers for each model here\n",
    "layers = {}\n",
    "for file in results_files:\n",
    "    # read json\n",
    "    with open(file, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    # extract the model name from the filename\n",
    "    model = re.search(r\"results/(.*?).json\", file).group(1)\n",
    "    # save layers without breaking df\n",
    "    layers[model] = results.pop(\"layers\")\n",
    "    for task_name, problem in results.items():\n",
    "        # add the data to the results (to be turned into df)\n",
    "        all_results.append({\n",
    "            \"task\": task_name,\n",
    "            \"model\": model,\n",
    "            \"model/task\": f\"{model}/{task_name}\"}\n",
    "            |\n",
    "            {\n",
    "                # keep attributes as arrays\n",
    "                problem_name: values\n",
    "                for problem_name, values in problem.items()\n",
    "            }\n",
    "        )\n",
    "# there is no model called \"gptr2-nano\" so save layers separately\n",
    "df = pd.DataFrame(all_results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up df into different groups\n",
    "resnet_df = df[df[\"model\"].str.match(r\"resnet\\d+$\")]\n",
    "# resort the resnet df (was alphabetical)\n",
    "# resnet_df = resnet_df.iloc[[2,3,4,0,1]]\n",
    "base_df = df[df[\"model\"].str.match(r\"[a-z0-9]+-base\")]\n",
    "large_df = df[df[\"model\"].str.match(r\"[a-z0-9]+-large\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic compose function\n",
    "compose = lambda *F: functools.reduce(lambda f, g: lambda x: f(g(x)), F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer_chart(results: pd.DataFrame, column: str, title: str = None, split=\"task\", transform=None):\n",
    "    \"\"\"plot a generic chart with attributes changing across layesr\"\"\"\n",
    "    # plot len(models) plots with len(splits) different attributes (can vary per model)\n",
    "    splits = results[split].unique()\n",
    "    models = results[\"model\"].unique()\n",
    "    fig, axes = plt.subplots(len(models))\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    data = []\n",
    "    for pivot in splits:\n",
    "        for model in models:\n",
    "            # calculate a sub-df for each split-model combination\n",
    "            sub_df = results[(results[split] == pivot) & (results[\"model\"] == model)]\n",
    "            # convert into a format seaborn likes\n",
    "            for i, row in sub_df.iterrows():\n",
    "                values = row[column]\n",
    "                for layer, value in enumerate(values):\n",
    "                    data.append({\n",
    "                        split: pivot,\n",
    "                        \"model\": model,\n",
    "                        \"layer\": layer,\n",
    "                        column: value\n",
    "                    })\n",
    "    # convert results to a dataframe\n",
    "    data = pd.DataFrame(data)\n",
    "    previous_tasks = None\n",
    "\n",
    "    # plot results on each axis\n",
    "    for i, model in enumerate(models):\n",
    "        ax = axes[i] if len(models) > 1 else axes\n",
    "        # plot a bar chart\n",
    "        sns.barplot(data[data[\"model\"] == model], x=\"layer\", y=column, hue=split, ax=ax)\n",
    "        tasks = data.loc[data[\"model\"] == model,split].unique()\n",
    "        # only put legend on first plot of each type\n",
    "        if set(tasks) == previous_tasks:\n",
    "            ax.get_legend().remove()\n",
    "        else:\n",
    "            previous_tasks = set(tasks)\n",
    "        # perform a transform to the axis\n",
    "        if transform is not None:\n",
    "            transform(ax)\n",
    "        # add vertical lines for resnets\n",
    "        if not all(layer[1] == 0 for layer in layers[model]):\n",
    "            for i, layer in enumerate(layers[model]):\n",
    "                # put the line between layers\n",
    "                if layer[1] == 0:\n",
    "                    ax.axvline(i - 0.5, ls=\"--\", color=sns.color_palette()[-2])\n",
    "        ax.set_title(model)\n",
    "        ax.set_xlabel(\"\")\n",
    "    plt.suptitle(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_chart(results: pd.DataFrame, column: str, title: str = None, split=\"task\", transform=None):\n",
    "    \"\"\"plot a generic chart with attributes changing across layesr\"\"\"\n",
    "    # plot len(models) plots with len(splits) different attributes (can vary per model)\n",
    "    splits = results[split].unique()\n",
    "    models = results[\"model\"].unique()\n",
    "    fig, axes = plt.subplots(sum(len(layers[model]) for model in models))\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    data = []\n",
    "    for pivot in splits:\n",
    "        for model in models:\n",
    "            # calculate a sub-df for each split-model combination\n",
    "            sub_df = results[(results[split] == pivot) & (results[\"model\"] == model)]\n",
    "            # convert into a format seaborn likes\n",
    "            for i, row in sub_df.iterrows():\n",
    "                values = row[column]\n",
    "                for layer, value in enumerate(values):\n",
    "                    for neuron, activation in enumerate(value):\n",
    "                        data.append({\n",
    "                            split: pivot,\n",
    "                            \"model\": model,\n",
    "                            \"layer\": layer,\n",
    "                            column: activation,\n",
    "                            \"neuron\": neuron,\n",
    "                        })\n",
    "    # convert results to a dataframe\n",
    "    data = pd.DataFrame(data)\n",
    "    previous_tasks = None\n",
    "    idx = 0\n",
    "\n",
    "    # plot results on each axis\n",
    "    for i, model in enumerate(models):\n",
    "        for j, layer in enumerate(layers[model]):\n",
    "            ax = axes[idx]\n",
    "            idx += 1\n",
    "            # plot a bar chart\n",
    "            model_layer = (data[\"model\"] == model) & (data[\"layer\"] == j)\n",
    "            sns.lineplot(data[model_layer], x=\"neuron\", y=column, hue=split, ax=ax)\n",
    "            tasks = data.loc[model_layer,split].unique()\n",
    "            # only put legend on first plot of each type\n",
    "            if set(tasks) == previous_tasks:\n",
    "                ax.get_legend().remove()\n",
    "            else:\n",
    "                previous_tasks = set(tasks)\n",
    "            # perform a transform to the axis\n",
    "            if transform is not None:\n",
    "                transform(ax)\n",
    "            ax.set_title(f\"{model}-{layer}\")\n",
    "            ax.set_xlabel(\"\")\n",
    "    plt.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_values(ax: plt.Axes) -> plt.Axes:\n",
    "    \"\"\"add values to each bar\"\"\"\n",
    "    # calculate the maximum height bar for reference\n",
    "    max_height = max([bar.get_height() for bar in ax.patches])\n",
    "    for bar, line in zip(ax.patches, ax.lines):\n",
    "        x = bar.get_x()\n",
    "        width = bar.get_width()\n",
    "        height = bar.get_height()\n",
    "        y = max(line.get_ydata())\n",
    "        # plot at the top of an error bar (if there is one) or bar\n",
    "        if np.isnan(y):\n",
    "            y = bar.get_height()\n",
    "        # plot with scaled font size and approximation of height shown\n",
    "        ax.text(x + width / 2., y + max_height / 50, f\"{height:.{int(height < 10)}f}\", ha=\"center\", va=\"bottom\", size=min(int(500 / len(ax.patches)), 12))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_horizontal_line(ax: plt.Axes, y: float) -> plt.Axes:\n",
    "    \"\"\"draw of horizontal line of a given height\"\"\"\n",
    "    ax.axhline(y=y, color=sns.color_palette()[-1], linestyle=\"--\", linewidth=1)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_chart(df, title=\"Distributions\", column=\"distribution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
